{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegNet model implemented with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duilio/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "\n",
    "from skimage.io import imread\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "os.environ['THEANO_FLAGS'] = 'mode=FAST_RUN, device=gpu0, floatX=float32, optimizer=fast_compile'\n",
    "\n",
    "#from keras.models import Sequential, Model\n",
    "from keras import models\n",
    "from keras.optimizers import SGD\n",
    "#from keras.optimizers import RMSprop, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'Data/'\n",
    "#img_w = 256\n",
    "#img_h = 256\n",
    "#n_labels = 2\n",
    "\n",
    "#n_train = 6\n",
    "#n_test = 3\n",
    "\n",
    "path = 'Data2/'\n",
    "img_w = 512\n",
    "img_h = 512\n",
    "n_labels = 4\n",
    "\n",
    "n_train = 50\n",
    "n_test = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map(labels):\n",
    "    label_map = np.zeros([img_h, img_w, n_labels])    \n",
    "    for r in range(img_h):\n",
    "        for c in range(img_w):\n",
    "            label_map[r, c, labels[r][c]] = 1\n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(mode):\n",
    "    assert mode in {'test', 'train'}, \\\n",
    "        'mode should be either \\'test\\' or \\'train\\''\n",
    "    data = []\n",
    "    label = []\n",
    "    df = pd.read_csv(path + mode + '.csv')\n",
    "    n = n_train if mode == 'train' else n_test\n",
    "    for i, item in df.iterrows():\n",
    "        if i >= n:\n",
    "            break\n",
    "        img, gt = [imread(path + item[0])], np.clip(imread(path + item[1]), 0, 1)\n",
    "        data.append(img)\n",
    "        label.append(label_map(gt))\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write(mode + \": [%-20s] %d%%\" % ('=' * int(20. * (i + 1) / n - 1) + '>',\n",
    "                                                    int(100. * (i + 1) / n)))\n",
    "        sys.stdout.flush()\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.flush()\n",
    "    data, label = np.array(data).reshape((n, img_h,img_w, 1)), np.array(label).reshape((n, img_h * img_w, n_labels))\n",
    "\n",
    "    print (mode + ': OK')\n",
    "    print ('\\tshapes: {}, {}'.format(data.shape, label.shape))\n",
    "    print ('\\ttypes:  {}, {}'.format(data.dtype, label.dtype))\n",
    "    print ('\\tmemory: {}, {} MB'.format(data.nbytes / 1048576, label.nbytes / 1048576))\n",
    "\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(output):\n",
    "    gt = []\n",
    "    df = pd.read_csv(path + 'test.csv')\n",
    "    for i, item in df.iterrows():\n",
    "        gt.append(np.clip(imread(path + item[1]), 0, 1))\n",
    "\n",
    "    plt.figure(figsize=(15, 2 * n_test))\n",
    "    for i, item in df.iterrows():\n",
    "        plt.subplot(n_test, 4, 4 * i + 1)\n",
    "        plt.title('Ground Truth')\n",
    "        plt.axis('off')\n",
    "        gt = imread(path + item[1])\n",
    "        plt.imshow(np.clip(gt, 0, 1))\n",
    "\n",
    "        plt.subplot(n_test, 4, 4 * i + 2)\n",
    "        plt.title('Prediction')\n",
    "        plt.axis('off')\n",
    "        labeled = np.argmax(output[i], axis=-1)\n",
    "        plt.imshow(labeled)\n",
    "\n",
    "        plt.subplot(n_test, 4, 4 * i + 3)\n",
    "        plt.title('Heat map')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(output[i][:, :, 1])\n",
    "\n",
    "        plt.subplot(n_test, 4, 4 * i + 4)\n",
    "        plt.title('Comparison')\n",
    "        plt.axis('off')\n",
    "        rgb = np.empty((img_h, img_w, 3))\n",
    "        rgb[:, :, 0] = labeled\n",
    "        rgb[:, :, 1] = imread(path + item[0])\n",
    "        rgb[:, :, 2] = gt\n",
    "        plt.imshow(rgb)\n",
    "\n",
    "    plt.savefig('result.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and compiling model built with *'build_model.py'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled: OK\n"
     ]
    }
   ],
   "source": [
    "with open('editable_model_5l.json') as model_file:\n",
    "    autoencoder = models.model_from_json(model_file.read())\n",
    "\n",
    "optimizer = SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False)\n",
    "autoencoder.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "print ('Compiled: OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model or load existing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: OK==================>] 100%\n",
      "\tshapes: (50, 512, 512, 1), (50, 262144, 4)\n",
      "\ttypes:  uint8, float64\n",
      "\tmemory: 12.5, 400.0 MB\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label = prep_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duilio/anaconda3/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nb_epoch = 2\n",
    "batch_size = 5\n",
    "history = autoencoder.fit(train_data, train_label, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1)\n",
    "autoencoder.save_weights('model_5l_weight_ep50.hdf5')\n",
    "\n",
    "#autoencoder.load_weights('model_5l_weight_ep50.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.utils.visualize_util'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1a4aec4bac59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.utils.visualize_util'"
     ]
    }
   ],
   "source": [
    "from keras.utils.visualize_util import plot\n",
    "plot(autoencoder, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testing data and evaluate score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: OK==================>] 100%\n",
      "\tshapes: (20, 512, 512, 1), (20, 262144, 4)\n",
      "\ttypes:  uint8, float64\n",
      "\tmemory: 5.0, 160.0 MB\n"
     ]
    }
   ],
   "source": [
    "test_data, test_label = prep_data('test')\n",
    "score = autoencoder.evaluate(test_data, test_label, verbose=0)\n",
    "print ('Test score:', score[0])\n",
    "print ('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4ae097e7c036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "output = autoencoder.predict_proba(test_data, verbose=0)\n",
    "output = output.reshape((output.shape[0], img_h, img_w, n_labels))\n",
    "\n",
    "plot_results(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
